# 智能 UI 测试猿 (Brilliant Monkey UI Tester)

> 方案只针对 UI，非 UI 部分的 unit test 还是常规的代码用例测试

## 背景

目前 Web 的 UI 测试基本都是写测试代码并模拟数据来进行 UI、交互、功能测试。该方式由写相应代码部分的程序员来自行
判断如何构造能反馈 UI、交互、功能符合预期的测试用例。

此方式好处在于程序员完全了解相应的代码逻辑，并由此可得出较准确的细粒度测试用例。

但是由于测试用例书写、数据模拟、交互模拟的繁琐和耗时，细粒度的测试用例往往是不可能的。另外，正如上面所提到的，测试用例
是基于程序员对于自己实现的校验，对 UI 和交互往往局限于自己的理解，导致测试用例有可能都在往符合自己预期的方向上构建。

## 解决方案

这里提出的解决方案，__智能 UI 测试猿__，则是从用户方体验得出的一套测试方式。该方式大概思路如下：
1. 测试由随机的交互开始，如鼠标交互、键盘交互等，并根据反馈结果进行下一步测试或者结束，组成交互链路的一部分
2. 测试链路还可人工干预生成
3. 一个测试过程由 __一个交互链路__ 组成
4. 一次完整的测试由随机的 __几个测试链路__ 组成
5. 测试的结果正确性可以进行人工干预，不干预情况下则对比交互后的结果截图来进行差异判断得出

该测试方案基于 Monkey Test 测试方式，并根据 Web 的交互方式进行一些优化。该方案会有 __3 个阶段__：
1. 简单的交互和截图差异对比判断正确性、Web 运行状态判断的 __Dump Monkey__
2. 可以进行完成交互链条并使用 AI 判断正确性的 __Smart Monkey__
3. 引入 AI 进行真实用户交互行为模拟和正确性判断的 __Brilliant Monkey__

## 方案的优点
1. 测试无需理会程序的实现逻辑，因此无需开发人员耗费时间去构建测试用例
2. 测试不需要考虑各个项目的差异，__对项目无任何侵入性__
3. 除了手动触发测试外，可以常规化随机测试，达到 __实时监控__ 项目的目的
4. 测试链路的人工干预可支持测试人员、客户支持人员等非开发专业人员操作，任何人均可以添加自己视角上的必要测试
5. 测试链路随机性可以 __模拟实际用户__ 可能产生的预期和非预期交互，达到真正的测试覆盖
6. 很容易作为一个第三方服务，以平台化方式服务于各个项目，甚至可行性验证后可以作为一项企业服务

## 方案的缺点
1. UI 的正确性无法得到准确反馈，不过这部分在开发过程的 UI 校稿环节做了一定的工作，因此可以认为无需处理或人工干预处理
2. 目前市面上没有发现类似的成熟方案可以参考借鉴，因此整个方案需要从头开始开发。

## 具体随机测试过程构思
1. 进入项目可访问地址，生成网站整体指标信息记录
2. 随机产生一次鼠标/键盘输入交互，等待产生的结果发生并截图
    - 无任何反馈
    - 同步性质反馈
    - 异步性质反馈
3. 进行下一次交互，等待产生的结果发生并截图
    - Dump Monkey 阶段随机产生交互行为,此阶段可以根据反馈的结果来限定交互区域和行为，以此产生可能符合预期的交互
    - Smart/Brilliant Monkey 阶段根据结果预测接下去应该采取的交互
    - 上两种为采取符合预期的交互，还应该随机产生不符合预期的交互，因此这里有可能产生多个交互链分支
4. 重复执行 *3*，直到符合结束的条件
    - 无任何反馈
    - 达到交互上限
    - 脱离了本测试链路环境，如页面跳转

## 可预期的难点
1. 辨别和跟踪一个交互物体在不同截图内的行为
2. 判断差异是可忽略的常规调整还是异常, 如样式、文案调整
3. AI 的交互行为决策

## 与现有 UI 测试方案（如 Airtest等）的比较

|比较|Brilliant Monkey UI Tester | Airtest等 UI 测试工具|
|----|----|----------
用例生成|可自动生成或人工干预生成，<br>人工生成跟 Airtest 类似|人工操作工具或写代码生成
预期校验|模拟人的预期，下一次用例路径的过程和结果<br>与上一次的预期一致性校验|手动加入断言，根据断言执行结果判断
优点|查看上面优点部分|已有成熟方案，工具链完整，操作简便。
缺点|查看上面缺点部分|创建和维护测试用例必须人工进行

#### 比较总结
1. 完成测试是否一定需要人工参与
2. 测试视角是用户或者开发测试人员
3. 是否需要项目配置支持


> CHANGE LOG
>
> 2019.08.05 枫叶
