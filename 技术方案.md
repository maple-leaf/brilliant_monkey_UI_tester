# 技术方案

## 系统组成部分
1. 前端交互模块 - 负责页面访问，页面交互，页面截图
2. 交互工厂模块 - 使用或不使用 AI 来预测和产生下一个交互动作
3. 结果评判模块 - 使用像素对比或 AI 来进行结果正确性的判断

## 前端交互模块

#### 功能定义

使用无头 Chrome 浏览器来进行被测试页面的访问、分析、交互，并将产生的结果截图。

#### 访问与分析
1. 页面被访问后有初始化的各种过程，本模块会使用 lighthouse 记录和分析页面载入时间、页面可交互时间、资源加载统计等。
2. 页面交互后会改变页面和内部 DOM 的状态，如输入框聚焦等，本模块会搜集交互工厂模块需要的页面状态,和交互结果截图一并交与其他模块。

#### 交互
使用 puppeteer 提供的 API 操作无头 Chrome 进行相应的交互行为，如点击、键盘输入、拖拽等。

#### 交互结果截图
使用 puppeteer 提供的 API 操作无头 Chrome 在交互完成后并产生一定结果后截图，以此作为当次交互产生的结果图。
交互结果可能有以下三种情况：
1. 无效交互，即本次交互不产生任何 UI 方面的影响。
2. 同步交互，即本次交互对 UI 产生了影响，且和 UI 变化是实时同步的。
3. 异步交互，即本次交互对 UI 产生了影响，但是影响是在一定的延迟后产生的。延迟可能产生的原因有代码执行时延，网络请求时延等。
交互结果截图无论是上面哪种情况，都应该保证结果图能正确的反馈交互的影响。

## 交互工厂模块

#### 功能定义

根据之前的交互结果预测和产生下一次前端交互模块应该在哪个目标上采取的哪一种交互行为。

#### 交互结果
交互结果由前端交互模块提供，包含两部分：
1. 页面和内部 DOM 的状态
2. 交互结果截图

#### 交互目标的确定逻辑
1. 随机交互目标
  - 假设对网页无任何认知情况下的随机目标
  - 视觉上最突出位置作为目标
  - 符合网页视觉热点模型下的随机目标，如 F 模型等。参考 [Eye Tracking and Web Experience](https://pdfs.semanticscholar.org/5e7f/f7f1d5ca6e4db19bb017fd054af8785ac028.pdf)
2. 根据交互结果确定交互目标： 根据结果限制可交互区域，在使用上面随机方式的任一种确定交互目标

#### 无 AI 介入下的交互预测
1. 没有任何之前交互结果信息下，对交互目标随机产生一次鼠标点击或者移动。
2. 之前已经产生过交互结果，根据交互结果确定下一次交互行为。比如以下场景:
  - 上次交互结果是展开了下拉列表，则下一次预期的交互行为是点击下拉内的某一项。
  - 上次交互结果是聚焦了输入框，则下一次预期的交互行为是键盘输入
  - 前面几次交互结果是位移了某些视觉元素，则下一次预期的交互行为可能是鼠标移动或者松开鼠标

#### 有 AI 介入下的交互预测
与无 AI 时基本一致，但是下一次预期交互行为的判断则由 AI 根据已经掌握的信息模拟人的行为模式进行。

## 结果评判模块

#### 功能定义
根据交互结果截图与基准测试交互结果截图对比来判断本次测试是否符合预期。

#### 一次完整测试的定义
在确定这个定义之前，我们需要先了解 __交互链__ 的定义。根据前面交互工厂的定义，之前的交互结果产生当前交互，当前交互的结果会产生下一次交互，那么这几次的交互就共同组成了一个交互链，即交互链是多个前后影响的交互组合。
那么一次完整的测试就是正确完成了一次之前或者本次生成的交互链。

#### 基准测试

## 以 puppeteer 调用无头 Chrome 浏览器对被测试页面进行一次随机测试为例

1. 无头 Chrome 访问被测试页面地址，进行页面分析和初始截图
2. 交互工厂产生一次交互动作定义提交给前端交互模块
3. 前端交互模块在无头 Chrome 内触发交互动作
4. 前端交互模块将这次动作产生的结果截图
